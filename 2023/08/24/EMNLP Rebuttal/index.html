<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"moriarty0923.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="EMNLP RebuttalReviewer ZqC6Reasons To Reject: The authors claim to evaluate their method on various open-source models but do not explain which models were evaluated, only the small alpaca models. It">
<meta property="og:type" content="article">
<meta property="og:title" content="Moriarty&#39; blog">
<meta property="og:url" content="https://moriarty0923.github.io/2023/08/24/EMNLP%20Rebuttal/index.html">
<meta property="og:site_name" content="Moriarty&#39; blog">
<meta property="og:description" content="EMNLP RebuttalReviewer ZqC6Reasons To Reject: The authors claim to evaluate their method on various open-source models but do not explain which models were evaluated, only the small alpaca models. It">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-08-24T10:57:37.917Z">
<meta property="article:modified_time" content="2023-08-29T11:45:31.108Z">
<meta property="article:author" content="Moriarty">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://moriarty0923.github.io/2023/08/24/EMNLP%20Rebuttal/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title> | Moriarty' blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Moriarty' blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-books">

    <a href="/books/" rel="section"><i class="fa fa-calendar fa-fw"></i>books</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://moriarty0923.github.io/2023/08/24/EMNLP%20Rebuttal/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Moriarty">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Moriarty' blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-08-24 18:57:37" itemprop="dateCreated datePublished" datetime="2023-08-24T18:57:37+08:00">2023-08-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-08-29 19:45:31" itemprop="dateModified" datetime="2023-08-29T19:45:31+08:00">2023-08-29</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="EMNLP-Rebuttal"><a href="#EMNLP-Rebuttal" class="headerlink" title="EMNLP Rebuttal"></a>EMNLP Rebuttal</h1><h2 id="Reviewer-ZqC6"><a href="#Reviewer-ZqC6" class="headerlink" title="Reviewer ZqC6"></a>Reviewer ZqC6</h2><h4 id="Reasons-To-Reject"><a href="#Reasons-To-Reject" class="headerlink" title="Reasons To Reject:"></a><strong>Reasons To Reject:</strong></h4><ul>
<li><p><em><strong>The authors claim to evaluate their method on various open-source models but do not explain which models were evaluated, only the small alpaca models. It seems odd not to compare with available larger open-source language models such as OPT and BLOOM. The authors do not report on budget and CO2 emissions, which is an important aspect of research on LLMs</strong></em></p>
<ul>
<li><p>We appreciate the feedback regarding our evaluation of open-source models in our paper. We apologize for the confusion caused by our statement about evaluating on various open-source models, and a more accurate statement would be “evaluating on various models”. <strong>While our main experiments were conducted on the 175B GPT-3.5 model,</strong> <strong>we believe it is valuable to further validate our approach on smaller-scale models, so we chose the small alpaca models. Regarding the OPT and BLOOM models, we have conducted additional experiments on GSM8K dataset and the results are as follows:</strong></p>
<table>
<thead>
<tr>
<th>Models</th>
<th>BLOOM-</th>
<th>OPT-</th>
</tr>
</thead>
<tbody><tr>
<td>Manual-CoT</td>
<td></td>
<td></td>
</tr>
<tr>
<td>IE-CoT</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>We also understand the importance of considering budget and CO2 emissions in language model research. Unfortunately, <strong>due to some policy restrictions</strong>, we cannot provide a specific breakdown of our budget. However, we can estimate the cost based on the charging guidelines of the OpenAI API. Evaluating on a 100-instance test set costs approximately <strong>（0.3-0.5）</strong> US dollars for greedy decoding (1 output chain). It’s worth noting that the cost may vary depending on the number of tokens and the specific model used. In our analysis experiments, we primarily utilized the GPT-3.5-Turbo model, as it offers a more cost-effective solution compared to text-davinci-002. Regarding CO2 emissions, since our experiments primarily focus on the inference stage of LLMs and the GPT3.5 models are closed-source, we lack specific information about the emissions. However, our IE-SC can effectively decrease the computational cost for self-consistency settings, as mentioned in our paper.</p>
</li>
</ul>
</li>
<li><p><em><strong>It is important to notice that language&#x2F;discourse-based reasoning, different from reasoning in general, may be affected by the linguistic characteristics of the language used in the work. While the work solely relies on reasoning in English, the authors fail to acknowledge or consider how syntactic, semantic and pragmatic aspects of the language may have impacted their work and whether their results may generalise to other languages.</strong></em></p>
<ul>
<li>Thank you for bringing up these important points. It is indeed crucial the impact of linguistic characteristics on language&#x2F;discourse-based reasoning. We acknowledge that our work have not explicitly addressed how syntactic, semantic, and pragmatic aspects of the language may have influenced our findings. The focus of this paper, however, is on how to select or construct better CoT examples through simple analysis of the data in the training set, rather than how linguistic characteristics would affect the performance of large models on reasoning tasks. Our findings can serve as a starting point for researchers interested in exploring the impact of language-specific features on reasoning tasks. In addition, we have conducted some additional experiments in other language, the results are as follows:</li>
</ul>
</li>
</ul>
<p>​			( 贴 实 验 ) 其他语言</p>
<h4 id="Typos-Grammar-Style-And-Presentation-Improvements"><a href="#Typos-Grammar-Style-And-Presentation-Improvements" class="headerlink" title="Typos Grammar Style And Presentation Improvements:"></a><strong>Typos Grammar Style And Presentation Improvements:</strong></h4><ul>
<li><del><em><strong>pg 2 line 109: we extend apply -&gt; we extend? pg 2 line 116: Cot generation -&gt; CoT generation pg 7 Table 2: Rondom -&gt; Random</strong></em></del><ul>
<li>We have corrected the other presentation&#x2F;typos&#x2F;grammatical errors listed in your comments. Thank you again for your patient and valuable proofreading.</li>
</ul>
</li>
</ul>
<h4 id="Questions-For-The-Authors"><a href="#Questions-For-The-Authors" class="headerlink" title="Questions For The Authors:"></a><strong>Questions For The Authors:</strong></h4><ul>
<li><p><em><strong>On what task has the evaluation on open-source models conducted, and why is gpt-3.5-Turbo listed as open-source? On which open-source models do the authors evaluate their framework?</strong></em></p>
<ul>
<li><p>The evaluation was conducted on the GSM8K benchmark in the “Robustness of INFORM” section. Regarding the mention of GPT-3.5 Turbo as open-source, we apologize for any confusion caused. Our intention was to highlight that we evaluated our framework on various models, including both open-source and close-source ones. We understand that this statement may have been misleading, and we apologize for the lack of clarity in our original paper, we will make the necessary corrections in the later version of the paper.</p>
<p>We have evaluated our framework on the alpaca 7b and alpaca-13b models. To further prove the robustness of INFORM, we have conducted additional experiments on opt and bloom models and the results are as follows:</p>
</li>
</ul>
</li>
</ul>
<p>​			( 贴 实 验 ，可以和q1 合并) </p>
<h2 id="Reviewer-tD1V"><a href="#Reviewer-tD1V" class="headerlink" title="Reviewer tD1V"></a>Reviewer tD1V</h2><p><strong>Questions For The Authors:</strong></p>
<ul>
<li><p><del>*<strong>In the subsection Robustness of INFORM, which benchmark do you refer to?</strong></del>*</p>
<ul>
<li>The evaluation was conducted on the GSM8K benchmark in the “Robustness of INFORM” section. We understand that this was not explicitly stated, and we apologize for any confusion caused.</li>
</ul>
</li>
<li><p><em><strong>How do you derive the values for H_min, H_max, N_min, and N_max?</strong></em></p>
<ul>
<li><p>As mentioned after equation 3 in our paper, H_min and H_max represent the minimum and maximum IE scores of the candidates, respectively. These values are calculated by equation 1 on different datasets. Typically, we have observed the values are 3 and 8.</p>
<p>Regarding N_min and N_max, they indicate the minimum and maximum numbers of samplings for self-consistency. In our experiment, we followed the approach proposed by Wang et al. [1] and selected 5 as the value for N_min. And the reason we selected 20 for N_max was based on our previous experiments, where we found that increasing the number of samplings beyond 20 did not yield significant further improvements in self-consistency. We believe that these values strike a balance between computational efficiency and achieving desirable results. We appreciate the reviewer’s inquiry, and we hope this explanation clarifies the rationale behind our choices.</p>
</li>
</ul>
</li>
<li><p><em><strong>Could you kindly specify the whole process of how you apply Equation 1 in the process of IE Ranking?</strong></em></p>
</li>
</ul>
<p>​			<strong>unigram</strong></p>
<p>[1] Wang X, Wei J, Schuurmans D, et al. Self-Consistency Improves Chain of Thought Reasoning in Language Models[C]&#x2F;&#x2F;The Eleventh International Conference on Learning Representations. 2023.</p>
<h2 id="Reviewer-ZjNo"><a href="#Reviewer-ZjNo" class="headerlink" title="Reviewer ZjNo"></a>Reviewer ZjNo</h2><p><strong>Questions For The Authors:</strong></p>
<ul>
<li><p><em><strong>Can you confirm that the entropy calculations are done on the unigrams? It’s not really clear from the paper, but this is what I inferred from the code. Why not use the model logits for text-davinci-003 at least?</strong></em></p>
<ul>
<li><p><del>Your understanding is correct. Actually, we have Since our experiments primarily focused on reasoning datasets containing numerous Arabic numerals and mathematical symbols, we observed that calculating entropy using unigrams better reflected the information content in such sentences in early experiments. As for why we did not use model logits, our intention was to perform simple manipulations and select the best examples for our experiments. Calculating model logits for all the questions in the training dataset can be computationally expensive and may not be suitable for many scenarios. Additionally, it’s worth noting that we extend our method to context generation and final result selection stages. Therefore, we opted for a more efficient approach to ensure feasibility within our overall framework, using unigrams for entropy calculations could be a deliberate choice due to certain trade-offs. However, we acknowledge that there may be other potentially superior methods for calculating information entropy.</del></p>
</li>
<li><p><strong>Your understanding is correct. Actually, we have tried several methods to compute information entropy in our early experiments, including using model logits. However, we ultimately chose to use the unigram approach for the following reasons:</strong></p>
<ol>
<li><p><strong>Our experiments primarily focused on reasoning datasets containing numerous Arabic numerals and mathematical symbols. Logits from models that were not specifically trained on such data may not accurately capture the desired information. On the other hand, using unigrams can brtter reflect the information since it is more directly based on the frequency distribution of individual words.</strong></p>
</li>
<li><p><strong>Our goal is to perform simple operations on the query in the training set and select the best examples. These queries are generally not too long, limiting the contextual information provided and making it challenging for the model to accurately understand the meaning and context of the sentence.</strong></p>
</li>
<li><p><strong>It’s worth noting that we extend our method to context generation and final result selection stages. Therefore, we opted for a more efficient approach to ensure feasibility within our overall framework. Using unigrams for entropy calculations could be a deliberate choice due to certain trade-offs.</strong></p>
</li>
</ol>
<p>   <strong>Based on the aforementioned three points, we have have chosen the unigram approach for computing information entropy. However, we acknowledge that model logits can yield comparable results in certain scenarios and there may be other potentially superior methods for calculating information entropy.</strong></p>
</li>
<li><p><del><em><strong>How are the Manual results obtained for datasets without CoT examples included?</strong></em></del></p>
</li>
<li><p>The manual results for datasets without CoT examples included were obtained by randomly selecting examples from the training set and manually composing chains of thought for them as we demonstrated in the Baseline part in section 4.1 Experiment settings. This process was followed based on the approach described by Wei et al. [1]. There is an example in MultiA dataset:</p>
<blockquote>
<p>Question: Tom bought 12 boxes of chocolate candy and gave 7 to his little brother. If each box has 6 pieces inside it, how many pieces did Tom still have?<br>Answer: Let’s think step by step.<br>Tom had 12 boxes of candy originally. Then he gave 7 to his little brother, so he had 12 - 7 &#x3D; 5 boxes of candy left. Each box has 6 pieces inside it, so Tom still had 5 x 6 &#x3D; 30 pieces.</p>
<p>Therefore, the answer (arabic numerals) is 30.</p>
</blockquote>
</li>
</ul>
</li>
<li><p><em><strong>The paper is written as though CoT was central, but actually four of seven the datasets have CoT strings included, and so all that is happening is that demonstrations are being selected and ranked. What happens if the include CoT strings are not used?</strong></em></p>
<ul>
<li><p>As we mentioned in the section3.3, when the data lacks annotated CoT,  we utilize our selection strategy to acquire a specific set of queries first. Following the approach outlined by Kojima et al. [2], rationale steps are generated through zero-shot CoT. We further integrated our method into the process of CoT generation. The effectiveness was shown in ‘’Effects of IE in CoT generation” part in section5.</p>
<p><strong>（补个无CoT 实验的结果，直接找）</strong></p>
</li>
</ul>
</li>
<li><p><em><strong>Are the results all based on single runs? If so, what is the observed variation across runs and across choices for the many hyperparameters that are in play here? If these hyperparameters were tuned informally based on pilot experiments, what examples were used for that and how extensively was this done across all the approaches?</strong></em></p>
<ul>
<li><p>Yes, most of our experiments were conducted based on single runs. In the absence of self-consistency setting, we set the temperature of models to 0, and there was no additional randomness in our example selection stage, which means that for a specific dataset, our inputs remained the same for each run, resulting in deterministic outcomes. However, in the self-consistency setting, we still relied on single runs as we believe that the self-consistency setup itself partially eliminates randomness and also helps in computational efficiency.</p>
<p>Regarding hyperparameters, we mostly followed the experimental settings of Wei et al.[1] and Wang et al.[3], such as the number of examples used for each dataset, temperature settings, and the minimum sampling count for self-consistency. As for the selection of H_min, H_max, and N_max, we have provided some insights in our response to reviewer tD1V. These parameters have been explored in their paper to understand their impact on the results. Additionally, there are other hyperparameters such as the number of CoT generations and the threshold for similarity pruning, which were set empirically. However, the focus of this paper is not on tuning these hyperparameters in every stage for their subtle effects on the results, but rather on exploring the contributions of each component. Perhaps in future work, more in-depth research can be conducted on these hyperparameters.</p>
</li>
</ul>
</li>
</ul>
<p>[1] Wei J, Wang X, Schuurmans D, et al. Chain-of-thought prompting elicits reasoning in large language models[J]. Advances in Neural Information Processing Systems, 2022, 35: 24824-24837.</p>
<p>[2] Kojima T, Gu S S, Reid M, et al. Large language models are zero-shot reasoners[J]. Advances in neural information processing systems, 2022, 35: 22199-22213.</p>
<p>[3] Wang X, Wei J, Schuurmans D, et al. Self-Consistency Improves Chain of Thought Reasoning in Language Models[C]&#x2F;&#x2F;The Eleventh International Conference on Learning Representations. 2023.</p>
<h4 id="开头-x2F-结尾"><a href="#开头-x2F-结尾" class="headerlink" title="开头&#x2F;结尾"></a>开头&#x2F;结尾</h4><p>We thank the reviewer for taking the time to evaluate our work and provide valuable feedback. Here, we address the main concerns that were brought up.</p>
<p>We hope we have addresses all the questions, and would appreciate if the reviewer would re-consider the position on our submission. Please let us know if there are any additional concerns.</p>
<p>再去别人的回答找找</p>
<p><em><strong>We hope we have addressed all the questions and thank you again for your valuable feedback. Please let us know if there are any additional concerns</strong></em></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/08/23/INFORM-rebuttal/" rel="prev" title="INFORM-rebuttal">
      <i class="fa fa-chevron-left"></i> INFORM-rebuttal
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/09/04/fleeting-moments-of-stillness/" rel="next" title="fleeting-moments-of-stillness">
      fleeting-moments-of-stillness <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#EMNLP-Rebuttal"><span class="nav-number">1.</span> <span class="nav-text">EMNLP Rebuttal</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Reviewer-ZqC6"><span class="nav-number">1.1.</span> <span class="nav-text">Reviewer ZqC6</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Reasons-To-Reject"><span class="nav-number">1.1.0.1.</span> <span class="nav-text">Reasons To Reject:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Typos-Grammar-Style-And-Presentation-Improvements"><span class="nav-number">1.1.0.2.</span> <span class="nav-text">Typos Grammar Style And Presentation Improvements:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Questions-For-The-Authors"><span class="nav-number">1.1.0.3.</span> <span class="nav-text">Questions For The Authors:</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reviewer-tD1V"><span class="nav-number">1.2.</span> <span class="nav-text">Reviewer tD1V</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reviewer-ZjNo"><span class="nav-number">1.3.</span> <span class="nav-text">Reviewer ZjNo</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%80%E5%A4%B4-x2F-%E7%BB%93%E5%B0%BE"><span class="nav-number">1.3.0.1.</span> <span class="nav-text">开头&#x2F;结尾</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Moriarty</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">32</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://p7qnhh1nqx.feishu.cn/wiki/wikcnu4ROjCNXxoCk0jeOBmDwZc" title="https:&#x2F;&#x2F;p7qnhh1nqx.feishu.cn&#x2F;wiki&#x2F;wikcnu4ROjCNXxoCk0jeOBmDwZc" rel="noopener" target="_blank">工作日报</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://space.bilibili.com/14898606/favlist" title="https:&#x2F;&#x2F;space.bilibili.com&#x2F;14898606&#x2F;favlist" rel="noopener" target="_blank">学习资源</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Moriarty</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
